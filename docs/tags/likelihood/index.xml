<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Likelihood on Applied Biostatistics I</title>
    <link>https://s-peischl.github.io/ABS1/tags/likelihood/</link>
    <description>Recent content in Likelihood on Applied Biostatistics I</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://s-peischl.github.io/ABS1/tags/likelihood/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deriving a Likelihood</title>
      <link>https://s-peischl.github.io/ABS1/2020/11/06/deriving-a-likelihood/</link>
      <pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://s-peischl.github.io/ABS1/2020/11/06/deriving-a-likelihood/</guid>
      <description>In this post we are going to explore the likelihood, the log-likelihood and how to derive a maximum likelihood estimator for the parameters of a Poisson distribution.
We start by genearting a random data set:
set.seed(42) sample.size = 100 lambda = 2 x = rpois(sample.size,lambda) This is a sample from a Poisson distribution, with mean \(\lambda =2\). We sinterpret it as i.i.d. realizations of a random variable \(X\) and label the data points: \(x_1, x_2, \ldots, x_n\), where n is the sample size.</description>
    </item>
    
  </channel>
</rss>
